# ğŸ¤– Local AI Financial Analyst

A local RAG (Retrieval-Augmented Generation) tool that ingests financial reports and extracts structured data (Revenue, CEO, Risks, Guidance) using **Llama 3**, **LangChain**, and **ChromaDB**.



## ğŸš€ Features

* **Local & Private:** Runs entirely on your machine using Ollama (no API keys required).
* **Structured Extraction:** Converts unstructured text into structured CSV data.
* **Streamlit UI:** Interactive dashboard for uploading data, monitoring progress, and downloading results.
* **Robust Error Handling:** Automatically handles "Read-Only" file locks common with local databases on Windows.

## ğŸ› ï¸ Tech Stack

* **UI:** Streamlit
* **LLM Orchestration:** LangChain
* **Local LLM:** Ollama (Llama 3.2)
* **Vector Database:** ChromaDB
* **Language:** Python 3.10+



## âš¡ï¸Setup & Usage
Prerequisites
Python 3.10+ installed.

Ollama installed and running.

Pull the model: ollama pull llama3.2

# Clone repository
git clone https://github.com/KenjiFH/Comparitive-Analyst-Agent
cd financial-analyst-agent

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt


streamlit run app.py

## ğŸ“¦ Project Structure

![Architecture diagram](https://github.com/user-attachments/files/25308976/Architecture.diagram.pdf)


```text
â”œâ”€â”€ app.py                 # Main Streamlit dashboard
â”œâ”€â”€ ingest_worker.py       # Subprocess for safe DB deletion & ingestion
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ data/                  # Drop your .txt financial reports here
â”‚   â””â”€â”€ txt_files_med/     
â””â”€â”€ src/
    â”œâ”€â”€ agent.py           # Logic for prompting the LLM
    â”œâ”€â”€ database.py        # ChromaDB connection & settings
    â””â”€â”€ ingestion.py       # Text chunking & metadata tagging logic
```text


